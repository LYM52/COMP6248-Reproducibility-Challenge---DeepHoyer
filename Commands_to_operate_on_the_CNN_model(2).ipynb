{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commands to operate on the CNN model(2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0stpy4RcPHcD2Ej3zhmZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LYM52/COMP6248-Reproducibility-Challenge---DeepHoyer/blob/main/Commands_to_operate_on_the_CNN_model(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP270gj_MGJh",
        "outputId": "d272c558-2b2f-4750-899f-8e0966b11adb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcV1FBhYQtFH",
        "outputId": "2daaeedc-068f-4e1c-efb1-a59f102df459"
      },
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive/DeepHoyer-master/mnist/CNN\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['util.py',\n",
              " 'prun_tune_T.py',\n",
              " 'prun_tune_V.py',\n",
              " 'element.py',\n",
              " 'structure.py',\n",
              " 'net',\n",
              " '__pycache__',\n",
              " 'saves',\n",
              " 'data',\n",
              " 'log.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38UvChJOUT0w",
        "outputId": "8bf775f4-73e9-4c06-cfa0-dc68e81c76e1"
      },
      "source": [
        "!python structure.py --reg-type 0 # No regularizer; structure Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "LeNet_5(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n",
            "Param name           Shape                          Type           \n",
            "----------------------------------------------------------------------\n",
            "conv1.weight         torch.Size([20, 1, 5, 5])      torch.float32  \n",
            "conv1.bias           torch.Size([20])               torch.float32  \n",
            "conv2.weight         torch.Size([50, 20, 5, 5])     torch.float32  \n",
            "conv2.bias           torch.Size([50])               torch.float32  \n",
            "fc1.weight           torch.Size([500, 800])         torch.float32  \n",
            "fc1.bias             torch.Size([500])              torch.float32  \n",
            "fc2.weight           torch.Size([10, 500])          torch.float32  \n",
            "fc2.bias             torch.Size([10])               torch.float32  \n",
            "--- Initial training ---\n",
            "Train Epoch: 249 [50000/60000 ( 83%)]  Loss: 0.001  Reg: 0.000: 100% 250/250 [23:27<00:00,  5.63s/it]\n",
            "Test set: Average loss: 0.0307, Accuracy: 9922/10000 (99.22%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQDd-Uy-dIjF",
        "outputId": "acf9f1fb-8fd3-43f0-b044-81bf57fff209"
      },
      "source": [
        "!python structure.py --reg-type 1 # Group Lasso regularizer; structure Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "LeNet_5(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n",
            "Param name           Shape                          Type           \n",
            "----------------------------------------------------------------------\n",
            "conv1.weight         torch.Size([20, 1, 5, 5])      torch.float32  \n",
            "conv1.bias           torch.Size([20])               torch.float32  \n",
            "conv2.weight         torch.Size([50, 20, 5, 5])     torch.float32  \n",
            "conv2.bias           torch.Size([50])               torch.float32  \n",
            "fc1.weight           torch.Size([500, 800])         torch.float32  \n",
            "fc1.bias             torch.Size([500])              torch.float32  \n",
            "fc2.weight           torch.Size([10, 500])          torch.float32  \n",
            "fc2.bias             torch.Size([10])               torch.float32  \n",
            "--- Initial training ---\n",
            "Train Epoch: 249 [50000/60000 ( 83%)]  Loss: 0.090  Reg: 129.109: 100% 250/250 [26:44<00:00,  6.42s/it]\n",
            "Test set: Average loss: 0.0606, Accuracy: 9802/10000 (98.02%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ1uBeI7RcvG",
        "outputId": "f1b31f6c-dd20-44ce-f054-44927ca24355"
      },
      "source": [
        "!python structure.py --reg-type 2 --decay 0.1  # Group-HS regularizer; structure Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9913344it [03:47, 43598.55it/s]\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "29696it [00:00, 454681.37it/s]\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1649664it [00:25, 64860.82it/s]                 \n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "5120it [00:00, 22700672.81it/s]\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "LeNet_5(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n",
            "Param name           Shape                          Type           \n",
            "----------------------------------------------------------------------\n",
            "conv1.weight         torch.Size([20, 1, 5, 5])      torch.float32  \n",
            "conv1.bias           torch.Size([20])               torch.float32  \n",
            "conv2.weight         torch.Size([50, 20, 5, 5])     torch.float32  \n",
            "conv2.bias           torch.Size([50])               torch.float32  \n",
            "fc1.weight           torch.Size([500, 800])         torch.float32  \n",
            "fc1.bias             torch.Size([500])              torch.float32  \n",
            "fc2.weight           torch.Size([10, 500])          torch.float32  \n",
            "fc2.bias             torch.Size([10])               torch.float32  \n",
            "--- Initial training ---\n",
            "Train Epoch: 249 [50000/60000 ( 83%)]  Loss: 0.177  Reg: 9.770: 100% 250/250 [29:17<00:00,  7.03s/it]\n",
            "Test set: Average loss: 0.1328, Accuracy: 9598/10000 (95.98%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbPfFEarjOMr",
        "outputId": "75e5eadf-45fc-418d-ac82-10ac00a4558d"
      },
      "source": [
        "!python prun_tune_V.py --model saves/str_0.1_2 --sensitivity 0.008 # Using prun_tune_V.py to prune the model processed by Group-HS regularizer; structure Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "--- Pruning ---\n",
            "Pruning with threshold : 0.008026776313781738 for layer conv1.weight\n",
            "Pruning with threshold : 0.000332979679107666 for layer conv1.bias\n",
            "Pruning with threshold : 0.0011450058221817018 for layer conv2.weight\n",
            "Pruning with threshold : 0.0018397542238235475 for layer conv2.bias\n",
            "Pruning with threshold : 0.0003542270362377167 for layer fc1.weight\n",
            "Pruning with threshold : 0.0005815419554710389 for layer fc1.bias\n",
            "Pruning with threshold : 0.0026661338806152346 for layer fc2.weight\n",
            "Pruning with threshold : 0.015137401580810547 for layer fc2.bias\n",
            "conv1.weight         | nonzeros =      50 /     500 ( 10.00%) | total_pruned =     450 | shape = (20, 1, 5, 5)\n",
            "conv1.weight         | dim0 =       1 /       1 (100.00%) | dim1 =       2 /      20 ( 10.00%)\n",
            "conv1.bias           | nonzeros =      16 /      20 ( 80.00%) | total_pruned =       4 | shape = (20,)\n",
            "conv2.weight         | nonzeros =     149 /   25000 (  0.60%) | total_pruned =   24851 | shape = (50, 20, 5, 5)\n",
            "conv2.weight         | dim0 =       2 /      20 ( 10.00%) | dim1 =       3 /      50 (  6.00%)\n",
            "conv2.bias           | nonzeros =      38 /      50 ( 76.00%) | total_pruned =      12 | shape = (50,)\n",
            "fc1.weight           | nonzeros =     390 /  400000 (  0.10%) | total_pruned =  399610 | shape = (500, 800)\n",
            "fc1.weight           | dim0 =      50 /     800 (  6.25%) | dim1 =      10 /     500 (  2.00%)\n",
            "fc1.bias             | nonzeros =     389 /     500 ( 77.80%) | total_pruned =     111 | shape = (500,)\n",
            "fc2.weight           | nonzeros =      81 /    5000 (  1.62%) | total_pruned =    4919 | shape = (10, 500)\n",
            "fc2.weight           | dim0 =       9 /     500 (  1.80%) | dim1 =      10 /      10 (100.00%)\n",
            "fc2.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 1123, pruned : 429957, total: 431080, Compression rate :     383.86x  ( 99.74% pruned)\n",
            "--- Finetuning ---\n",
            "Best: 97.33% Train Epoch: 49 [50000/60000 ( 83%)]  Loss: 0.019917 Total: 0.019917: 100% 50/50 [06:51<00:00,  8.23s/it]\n",
            "Accuracy: 97.33%\n",
            "conv1.weight         | nonzeros =      50 /     500 ( 10.00%) | total_pruned =     450 | shape = (20, 1, 5, 5)\n",
            "conv1.weight         | dim0 =       1 /       1 (100.00%) | dim1 =       2 /      20 ( 10.00%)\n",
            "conv1.bias           | nonzeros =      16 /      20 ( 80.00%) | total_pruned =       4 | shape = (20,)\n",
            "conv2.weight         | nonzeros =     149 /   25000 (  0.60%) | total_pruned =   24851 | shape = (50, 20, 5, 5)\n",
            "conv2.weight         | dim0 =       2 /      20 ( 10.00%) | dim1 =       3 /      50 (  6.00%)\n",
            "conv2.bias           | nonzeros =      38 /      50 ( 76.00%) | total_pruned =      12 | shape = (50,)\n",
            "fc1.weight           | nonzeros =     390 /  400000 (  0.10%) | total_pruned =  399610 | shape = (500, 800)\n",
            "fc1.weight           | dim0 =      50 /     800 (  6.25%) | dim1 =      10 /     500 (  2.00%)\n",
            "fc1.bias             | nonzeros =     389 /     500 ( 77.80%) | total_pruned =     111 | shape = (500,)\n",
            "fc2.weight           | nonzeros =      81 /    5000 (  1.62%) | total_pruned =    4919 | shape = (10, 500)\n",
            "fc2.weight           | dim0 =       9 /     500 (  1.80%) | dim1 =      10 /      10 (100.00%)\n",
            "fc2.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 1123, pruned : 429957, total: 431080, Compression rate :     383.86x  ( 99.74% pruned)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j89MGYz4qsl6",
        "outputId": "97cf3de8-1d24-4015-bfe4-5b8aa8c5abbd"
      },
      "source": [
        "!python prun_tune_T.py --model saves/str_0.1_2 # Using prun_tune_T.py to prune the model processed by Group-HS regularizer; structure Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "--- Pruning ---\n",
            "Test set: Average loss: 0.1327, Accuracy: 9598/10000 (95.98%)\n",
            "conv1.weight         | nonzeros =      50 /     500 ( 10.00%) | total_pruned =     450 | shape = (20, 1, 5, 5)\n",
            "conv1.weight         | dim0 =       1 /       1 (100.00%) | dim1 =       2 /      20 ( 10.00%)\n",
            "conv1.bias           | nonzeros =      12 /      20 ( 60.00%) | total_pruned =       8 | shape = (20,)\n",
            "conv2.weight         | nonzeros =     149 /   25000 (  0.60%) | total_pruned =   24851 | shape = (50, 20, 5, 5)\n",
            "conv2.weight         | dim0 =       2 /      20 ( 10.00%) | dim1 =       3 /      50 (  6.00%)\n",
            "conv2.bias           | nonzeros =      41 /      50 ( 82.00%) | total_pruned =       9 | shape = (50,)\n",
            "fc1.weight           | nonzeros =     377 /  400000 (  0.09%) | total_pruned =  399623 | shape = (500, 800)\n",
            "fc1.weight           | dim0 =      49 /     800 (  6.12%) | dim1 =       9 /     500 (  1.80%)\n",
            "fc1.bias             | nonzeros =     320 /     500 ( 64.00%) | total_pruned =     180 | shape = (500,)\n",
            "fc2.weight           | nonzeros =      81 /    5000 (  1.62%) | total_pruned =    4919 | shape = (10, 500)\n",
            "fc2.weight           | dim0 =       9 /     500 (  1.80%) | dim1 =      10 /      10 (100.00%)\n",
            "fc2.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 1040, pruned : 430040, total: 431080, Compression rate :     414.50x  ( 99.76% pruned)\n",
            "--- Finetuning ---\n",
            "Train Epoch: 99 [50000/60000 ( 83%)]  Loss: 0.073930 Total: 0.073930: 100% 100/100 [18:00<00:00, 10.80s/it]\n",
            "Test set: Average loss: 0.0892, Accuracy: 9725/10000 (97.25%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr4pPJMf8NAr",
        "outputId": "6c4dacf6-c52c-4ff8-8c17-97689d325367"
      },
      "source": [
        "!python prun_tune_T.py --model saves/elt_0.001_0 # Using prun_tune_T.py to prune the model processed by no regularizer; Element-wise Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "--- Pruning ---\n",
            "Test set: Average loss: 0.0938, Accuracy: 9937/10000 (99.37%)\n",
            "conv1.weight         | nonzeros =     498 /     500 ( 99.60%) | total_pruned =       2 | shape = (20, 1, 5, 5)\n",
            "conv1.weight         | dim0 =       1 /       1 (100.00%) | dim1 =      20 /      20 (100.00%)\n",
            "conv1.bias           | nonzeros =      20 /      20 (100.00%) | total_pruned =       0 | shape = (20,)\n",
            "conv2.weight         | nonzeros =   24866 /   25000 ( 99.46%) | total_pruned =     134 | shape = (50, 20, 5, 5)\n",
            "conv2.weight         | dim0 =      20 /      20 (100.00%) | dim1 =      50 /      50 (100.00%)\n",
            "conv2.bias           | nonzeros =      50 /      50 (100.00%) | total_pruned =       0 | shape = (50,)\n",
            "fc1.weight           | nonzeros =  395637 /  400000 ( 98.91%) | total_pruned =    4363 | shape = (500, 800)\n",
            "fc1.weight           | dim0 =     800 /     800 (100.00%) | dim1 =     500 /     500 (100.00%)\n",
            "fc1.bias             | nonzeros =     493 /     500 ( 98.60%) | total_pruned =       7 | shape = (500,)\n",
            "fc2.weight           | nonzeros =    4955 /    5000 ( 99.10%) | total_pruned =      45 | shape = (10, 500)\n",
            "fc2.weight           | dim0 =     500 /     500 (100.00%) | dim1 =      10 /      10 (100.00%)\n",
            "fc2.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
            "alive: 426529, pruned : 4551, total: 431080, Compression rate :       1.01x  (  1.06% pruned)\n",
            "--- Finetuning ---\n",
            "Train Epoch: 99 [50000/60000 ( 83%)]  Loss: 0.000000 Total: 0.000000: 100% 100/100 [18:28<00:00, 11.08s/it]\n",
            "Test set: Average loss: 0.0944, Accuracy: 9937/10000 (99.37%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3DT3AjM73yo",
        "outputId": "f48e1eb0-3779-4cca-e33b-793ee39cb482"
      },
      "source": [
        "!python prun_tune_T.py --model saves/elt_0.01_2 # Using prun_tune_T.py to prune the model processed by Transformed Hoyer regularizer; element Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "--- Pruning ---\n",
            "Test set: Average loss: 0.0689, Accuracy: 9855/10000 (98.55%)\n",
            "conv1.weight         | nonzeros =     409 /     500 ( 81.80%) | total_pruned =      91 | shape = (20, 1, 5, 5)\n",
            "conv1.weight         | dim0 =       1 /       1 (100.00%) | dim1 =      18 /      20 ( 90.00%)\n",
            "conv1.bias           | nonzeros =       4 /      20 ( 20.00%) | total_pruned =      16 | shape = (20,)\n",
            "conv2.weight         | nonzeros =    8485 /   25000 ( 33.94%) | total_pruned =   16515 | shape = (50, 20, 5, 5)\n",
            "conv2.weight         | dim0 =      19 /      20 ( 95.00%) | dim1 =      49 /      50 ( 98.00%)\n",
            "conv2.bias           | nonzeros =      25 /      50 ( 50.00%) | total_pruned =      25 | shape = (50,)\n",
            "fc1.weight           | nonzeros =   45196 /  400000 ( 11.30%) | total_pruned =  354804 | shape = (500, 800)\n",
            "fc1.weight           | dim0 =     739 /     800 ( 92.38%) | dim1 =     422 /     500 ( 84.40%)\n",
            "fc1.bias             | nonzeros =      53 /     500 ( 10.60%) | total_pruned =     447 | shape = (500,)\n",
            "fc2.weight           | nonzeros =    1681 /    5000 ( 33.62%) | total_pruned =    3319 | shape = (10, 500)\n",
            "fc2.weight           | dim0 =     274 /     500 ( 54.80%) | dim1 =      10 /      10 (100.00%)\n",
            "fc2.bias             | nonzeros =       1 /      10 ( 10.00%) | total_pruned =       9 | shape = (10,)\n",
            "alive: 55854, pruned : 375226, total: 431080, Compression rate :       7.72x  ( 87.04% pruned)\n",
            "--- Finetuning ---\n",
            "Train Epoch: 99 [50000/60000 ( 83%)]  Loss: 0.000000 Total: 0.000000: 100% 100/100 [18:40<00:00, 11.21s/it]\n",
            "Test set: Average loss: 0.0960, Accuracy: 9911/10000 (99.11%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Q4l8k324w-",
        "outputId": "8845f8f6-2447-4312-d4ac-dd1ce1ebb79a"
      },
      "source": [
        "!python prun_tune_T.py --model saves/elt_0.0001_3 # Using prun_tune_T.py to prune the model processed by Transformed Hoyer-Square regularizer; element Pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "--- Pruning ---\n",
            "Test set: Average loss: 0.0823, Accuracy: 9890/10000 (98.90%)\n",
            "conv1.weight         | nonzeros =     457 /     500 ( 91.40%) | total_pruned =      43 | shape = (20, 1, 5, 5)\n",
            "conv1.weight         | dim0 =       1 /       1 (100.00%) | dim1 =      20 /      20 (100.00%)\n",
            "conv1.bias           | nonzeros =      14 /      20 ( 70.00%) | total_pruned =       6 | shape = (20,)\n",
            "conv2.weight         | nonzeros =    9159 /   25000 ( 36.64%) | total_pruned =   15841 | shape = (50, 20, 5, 5)\n",
            "conv2.weight         | dim0 =      20 /      20 (100.00%) | dim1 =      50 /      50 (100.00%)\n",
            "conv2.bias           | nonzeros =      14 /      50 ( 28.00%) | total_pruned =      36 | shape = (50,)\n",
            "fc1.weight           | nonzeros =   60477 /  400000 ( 15.12%) | total_pruned =  339523 | shape = (500, 800)\n",
            "fc1.weight           | dim0 =     661 /     800 ( 82.62%) | dim1 =     491 /     500 ( 98.20%)\n",
            "fc1.bias             | nonzeros =      80 /     500 ( 16.00%) | total_pruned =     420 | shape = (500,)\n",
            "fc2.weight           | nonzeros =    3158 /    5000 ( 63.16%) | total_pruned =    1842 | shape = (10, 500)\n",
            "fc2.weight           | dim0 =     447 /     500 ( 89.40%) | dim1 =      10 /      10 (100.00%)\n",
            "fc2.bias             | nonzeros =       6 /      10 ( 60.00%) | total_pruned =       4 | shape = (10,)\n",
            "alive: 73365, pruned : 357715, total: 431080, Compression rate :       5.88x  ( 82.98% pruned)\n",
            "--- Finetuning ---\n",
            "Train Epoch: 99 [50000/60000 ( 83%)]  Loss: 0.000000 Total: 0.000000: 100% 100/100 [18:23<00:00, 11.03s/it]\n",
            "Test set: Average loss: 0.0955, Accuracy: 9918/10000 (99.18%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKIGhcSs9ApJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}